{"cells":[{"cell_type":"code","execution_count":null,"id":"1a7aa925","metadata":{},"outputs":[],"source":["# https://www.kaggle.com/code/hitman1309/tutorial-23-02-24"]},{"cell_type":"markdown","metadata":{},"source":["# <span style='font-family:Georgia'> <span style='color:blue'> Deep Learning Tutorial Session - 23rd Feb 2024\n","\n","### Agenda - \n","- Installation in Local Machine\n","- Tensorflow vs Pytorch\n","- Exploring MNIST Dataset\n","- Implementing a Simple ANN for classifying digits from the MNIST Dataset  \n","- How to run code in Kaggle and Colab"]},{"cell_type":"markdown","metadata":{},"source":["---"]},{"cell_type":"markdown","metadata":{},"source":["## <span style='font-family:Georgia'> <span style='color:green'> Installation in Local Machine\n","\n","### Tensorflow : https://www.tensorflow.org/install/pip#windows-native\n","### Pytorch : https://pytorch.org/get-started/locally/"]},{"cell_type":"markdown","metadata":{},"source":["---"]},{"cell_type":"markdown","metadata":{},"source":["## <span style='font-family:Georgia'> <span style='color:green'> TensorFlow vs. PyTorch: A Comparative Guide for Deep Learning Tutorials\n","\n","Choosing the right deep learning framework is crucial for your tutorial. Here's a breakdown of TensorFlow and PyTorch, along with code samples:\n","\n","**Key Differences:**\n","\n","| Feature        | TensorFlow                                     | PyTorch                                    |\n","|----------------|----------------------------------------------|----------------------------------------------|\n","| Syntax         | Imperative, static computational graph   | Declarative, dynamic computational graph  |\n","| Learning Curve  | Steeper, requires understanding of dataflow      | Easier, intuitive and Pythonic         |\n","| Performance    | Generally faster for large models, lower memory usage | Potentially faster for small models, better debugging |\n","| Production     | Wide range of deployment options (TF Serving, TFLite) | Requires integration with web frameworks         |\n","| Community     | Larger, more established                        | Active, research-oriented community             |\n","| Pre-trained Models | Extensive library (TensorFlow Hub)             | Smaller library (PyTorch Hub)                 |\n","\n","**When to Use Which:**\n","\n","- **TensorFlow:**\n","    - Production deep learning (large models)\n","    - Advanced customization/low-level control\n","    - Existing TensorFlow knowledge/preference\n","- **PyTorch:**\n","    - Rapid prototyping/experimentation\n","    - Research/development (dynamic graph)\n","    - User preference for Pythonic syntax/flexibility\n","\n","**Code Samples:**\n","\n","**TensorFlow:**"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import tensorflow as tf\n","\n","# Simple neural network\n","inputs = tf.keras.Input(shape=(784,))\n","x = tf.keras.layers.Dense(64, activation='relu')(inputs)\n","outputs = tf.keras.layers.Dense(10, activation='softmax')(x)\n","\n","model = tf.keras.Model(inputs=inputs, outputs=outputs)\n","\n","# Compile and train\n","model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n","model.fit(x_train, y_train, epochs=5, batch_size=32)"]},{"cell_type":"markdown","metadata":{},"source":["**PyTorch:**"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import torch\n","\n","# Simple neural network\n","class Net(torch.nn.Module):\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        self.fc1 = torch.nn.Linear(784, 64)\n","        self.relu = torch.nn.ReLU()\n","        self.fc2 = torch.nn.Linear(64, 10)\n","\n","    def forward(self, x):\n","        x = self.fc1(x)\n","        x = self.relu(x)\n","        x = self.fc2(x)\n","        return x\n","\n","model = Net()\n","\n","# Loss and optimizer\n","criterion = torch.nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters())\n","\n","# Train\n","for epoch in range(5):\n","    for i, (data, target) in enumerate(train_loader):\n","        optimizer.zero_grad()\n","        outputs = model(data)\n","        loss = criterion(outputs, target)\n","        loss.backward()\n","        optimizer.step()"]},{"cell_type":"markdown","metadata":{},"source":["---"]},{"cell_type":"markdown","metadata":{},"source":["## <span style='font-family:Georgia'> <span style='color:green'> Exploring MNIST Dataset\n","\n","![mnist.png](https://cdn.analyticsvidhya.com/wp-content/uploads/2020/02/mnist.png)\n","\n","MNIST (Modified National Institute of Standards and Technology) is a well-known dataset used in Computer Vision that was built by Yann Le Cun et al. It is composed of images that are handwritten digits (0-9), split into a training set of 50,000 images and a test set of 10,000, where each image is 28 x 28 pixels in width and height."]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Some common imports\n","import os\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from keras.datasets import mnist\n","\n","# loading the dataset\n","(X_train, y_train), (X_test, y_test) = mnist.load_data()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["print(\"X_train shape\", X_train.shape)\n","print(\"y_train shape\", y_train.shape)\n","print(\"X_test shape\", X_test.shape)\n","print(\"y_test shape\", y_test.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["np.set_printoptions(linewidth=150)\n","print(X_train[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def visualize_input(img, ax):\n","    ax.imshow(img, cmap='summer')\n","    width, height = img.shape\n","    thresh = img.max()/2.5\n","    for x in range(width):\n","        for y in range(height):\n","            ax.annotate(str(round(img[x][y],2)), xy=(y,x),\n","                        horizontalalignment='center',\n","                        verticalalignment='center',\n","                        color='white' if img[x][y]<thresh else 'black')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["plt.imshow(X_train[0],\"gray\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["fig = plt.figure(figsize = (12,12)) \n","ax = fig.add_subplot(111)\n","visualize_input(X_train[0], ax)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["y_train[0]"]},{"cell_type":"markdown","metadata":{},"source":["---"]},{"cell_type":"markdown","metadata":{},"source":["## <span style='font-family:Georgia'> <span style='color:green'> Implementing a Simple ANN\n","\n","#### Steps -\n","- Flatten the input image dimensions to 1D (width pixels x height pixels)\n","- Normalize the image pixel values (divide by 255)\n","- One-Hot Encode the categorical column\n","- Build a model architecture (Sequential) with Dense layers(Fully connected layers)\n","- Train the model and make predictions\n","    \n","\n","![ann.gif](https://miro.medium.com/v2/resize:fit:720/format:webp/0*u5-PcKYVfUE5s2by.gif)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# keras imports for the dataset and building our neural network\n","from keras.datasets import mnist\n","import keras\n","from tensorflow.keras import layers\n","from keras.utils import to_categorical"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Flattening the images from the 28x28 pixels to 1D 787 pixels\n","X_train = X_train.reshape(60000, 784)\n","X_test = X_test.reshape(10000, 784)\n","X_train = X_train.astype('float32')\n","X_test = X_test.astype('float32')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# normalizing the data to help with the training\n","X_train /= 255\n","X_test /= 255"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["print(y_train[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# one-hot encoding using keras' numpy-related utilities\n","n_classes = 10\n","print(\"Shape before one-hot encoding: \", y_train.shape)\n","Y_train = keras.utils.to_categorical(y_train, n_classes)\n","Y_test = keras.utils.to_categorical(y_test, n_classes)\n","print(\"Shape after one-hot encoding: \", Y_train.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["print(Y_train[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#Creating base neural network\n","model = keras.Sequential([\n","    layers.Dense(128, activation='relu', input_shape=(784,)),\n","    layers.Dense(24, activation='relu'),  \n","    layers.Dense(10,activation='sigmoid'),\n","])\n","\n","model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["keras.utils.plot_model(model, show_shapes=True)"]},{"cell_type":"markdown","metadata":{},"source":["![loss.png](https://miro.medium.com/v2/resize:fit:640/format:webp/0*vteMfTAGWsIZSaOW)\n","\n","where, yi is the original label and yi cap is the predicted label"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#Compiling the model\n","model.compile(loss=\"categorical_crossentropy\",\n","              optimizer=\"sgd\",\n","              metrics = ['accuracy'])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["history = model.fit(X_train, Y_train, batch_size=100, epochs=30)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","# Plot training & validation accuracy values\n","plt.figure(figsize=(14,3))\n","\n","plt.subplot(1, 2, 1)\n","plt.plot(history.history['accuracy'])\n","plt.title('Model accuracy')\n","plt.ylabel('Accuracy')\n","plt.xlabel('Epoch')\n","plt.legend(['Train'], loc='upper left')\n","\n","# Plot training & validation loss values\n","plt.subplot(1, 2, 2)\n","plt.plot(history.history['loss'])\n","plt.title('Model loss')\n","plt.ylabel('Loss')\n","plt.xlabel('Epoch')\n","plt.legend(['Train'], loc='upper left')\n","\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["test_loss_digit, test_acc_digit = model.evaluate(X_test, Y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["print(\"Testing Accuracy : \", round(test_acc_digit,4)*100, \"%\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# plot the confusion matrix for the testing dataset\n","from sklearn.metrics import confusion_matrix\n","import seaborn as sns\n","\n","y_pred = model.predict(X_test)\n","\n","# Convert the predictions and true labels to classes (assuming one-hot encoding for true labels)\n","y_pred_classes = np.argmax(y_pred, axis=1)\n","y_true_classes = np.argmax(Y_test, axis=1)\n","\n","# Create the confusion matrix\n","conf_matrix = confusion_matrix(y_true_classes, y_pred_classes)\n","\n","# Plot the confusion matrix using seaborn\n","plt.figure(figsize=(8, 6))\n","sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=range(10), yticklabels=range(10))\n","plt.xlabel('Predicted')\n","plt.ylabel('True')\n","plt.title('Confusion Matrix')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# take one random sample from test and show the predicted vs actual\n","import random\n","i = random.randint(1,10000)\n","print(\"Random number is \", i)\n","plt.imshow(X_test[i].reshape(28,28), cmap='gray')\n","plt.show()\n","print(\"Actual number is \", y_test[i])\n","print(\"Predicted number is \", model.predict(X_test[i].reshape(1,784)).argmax())"]},{"cell_type":"markdown","metadata":{},"source":["---"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import cv2\n","\n","img = cv2.imread('/kaggle/input/tutorial-23-1/blank_0.png',0)\n","\n","plt.imshow(img,\"gray\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["print(\"Predicted number is \", model.predict(img.reshape(1,784)).argmax())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30646,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":5}
